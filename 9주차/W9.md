
- [Book Chapter 4.](#book-chapter-4)
    - [📌 What is Loss Function](#-what-is-loss-function)
      - [1. Definition of Loss Function](#1-definition-of-loss-function)
      - [2. Optimizer](#2-optimizer)
        - [2-1. 기본형: Gradient Descent (GD)](#2-1-기본형-gradient-descent-gd)
          - [2-1-1. Batch Gradient Descent](#2-1-1-batch-gradient-descent)


# <span style="color:red">Book Chapter 4.</span>

### 📌 What is Loss Function

#### 1. Definition of Loss Function

Loss Function은 우리가 만든 모델의 예측값이 실제 데이터와 차이가 얼마나 나는지 수치적으로 정량화한 지표이다.

학습, 즉 fitting을 진행할 때, 우리는 input data x와 output data y 사이의 관계 (mapping)을 찾아가게 된다. 이 과정에서 가중치를 조정하게 되며, loss function이 적절한 가중치를 찾아가는 방향을 제시하게 되는 것이다.

#### 2. Optimizer

loss를 줄이는 방향으로 학습을 진행시키는 알고리즘을 optimizer라고 한다. 그럼 어떤 optimizer가 있을까?


##### 2-1. 기본형: Gradient Descent (GD)

###### 2-1-1. Batch Gradient Descent

- 전체 데이터셋을 기준으로 한 번의 경사 하강
- 장점 : 메모리 효율적임, 업데이트가 빠름
- 진동이 심하고 최적점 근처에서 불안정함.
  

<pre>'''matlab
function W = DeltaSGD(W, X, D)
    alpha =0.9;
    N =4;
    for k =1:N
        x = X(k, :);
        d = D(k);
        v = W*x;
        y = Sigmoid(v);
        e = d - y;
        delta = y*(1-y)*e;
        dW = alpha*delta*x;
        W(1) = W(1) + dW(1);
        W(2) = W(2) + dW(2);
        W(3) = W(3) + dW(3);
    end
end
'''
</pre>